{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9956278f",
   "metadata": {},
   "source": [
    "# Machine_learning_fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d585146e",
   "metadata": {},
   "source": [
    "# Split data\n",
    "*for avoid overfitting*\n",
    "* Training dataset\n",
    "* Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "132f534a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, prob):\n",
    "    \"\"\"split data into fractions [prob, 1 - prob]\"\"\"\n",
    "    results = [], []\n",
    "    for row in data:\n",
    "        results[0 if random.random() < prob else 1].append(row)\n",
    "        \n",
    "def train_test_split(x, y, test_pct):\n",
    "    data = list(zip(x, y)) # pair corresponding values\n",
    "    train, test = split_data(data, 1 - test_pct) # split the dataset of pairs\n",
    "    x_train, y_train = list(zip(*train)) # magical un-zip trick\n",
    "    x_test, y_test = list(zip(*test))\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037f4857",
   "metadata": {},
   "source": [
    "sklearn's train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61f1c951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<데이터 split 전>\n",
      "[[ 0  1]\n",
      " [ 2  3]\n",
      " [ 4  5]\n",
      " [ 6  7]\n",
      " [ 8  9]\n",
      " [10 11]]\n",
      "[0, 1, 2, 3, 4, 5]\n",
      "\n",
      "<데이터 split 후>\n",
      "[[ 2  3]\n",
      " [10 11]\n",
      " [ 4  5]\n",
      " [ 8  9]] [1, 5, 2, 4]\n",
      "[[6 7]\n",
      " [0 1]] [3, 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = np.arange(12).reshape((6, 2)), list(range(6))\n",
    "print(\"<데이터 split 전>\")\n",
    "print(X)\n",
    "print(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "print(\"\\n<데이터 split 후>\")\n",
    "print(X_train, y_train)\n",
    "print(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a025484",
   "metadata": {},
   "source": [
    "# Correctness\n",
    "## accuracy\n",
    "* correct/total   \n",
    "$(tp+tn)/(tp+tn+fp+fn)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3de61d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(tp, fp, fn, tn):\n",
    "    correct = tp + tn\n",
    "    total = tp + fp + fn + tn\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70da245a",
   "metadata": {},
   "source": [
    "## Precision(정밀도)\n",
    "\n",
    " *how accurate our positive predictions were*\n",
    "\n",
    "> Positive 라고 예측한 것 중에 True positive\n",
    "\n",
    "* TP/TP+FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ae6b3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(tp, fp, fn, tn):\n",
    "    return tp/ (tp+fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891a2a58",
   "metadata": {},
   "source": [
    "## Recall(재현율)\n",
    "\n",
    "*what fraction of the positives our model identified*\n",
    "\n",
    "> Positve 인 것 중에 True positive\n",
    "\n",
    "* TP/TP+FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9613367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(tp, fp, fn, tn):\n",
    "    return tp/(tp+fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173aa16d",
   "metadata": {},
   "source": [
    "## f1_score\n",
    "\n",
    "* 2xPxR/(P+R)\n",
    "\n",
    "> Precision 과 Recall 간의 조화평균\n",
    "* 어느 한쪽으로 치우치지 않을 때 조화롭게 높은 값\n",
    "* 경우에 따라 Precision 과 Recall 의 중요도를 다르다.\n",
    "\n",
    "* Precision 과 Recall 은 반비례 관계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99d0bb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(tp, fp, fn, tn):\n",
    "    p = precision(tp, fp, fn, tn)\n",
    "    r = recall(tp, fp, fn, tn)\n",
    "    return 2*p*r/(p+r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f79c38f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision(70, 4930, 13930, 981070) = 0.014\n",
      "recall(70, 4930, 13930, 981070) = 0.005\n",
      "f1_score(70, 4930, 13930, 981070) = 0.00736842105263158\n"
     ]
    }
   ],
   "source": [
    "print(\"precision(70, 4930, 13930, 981070) = {}\".format(precision(70, 4930, 13930, 981070)))\n",
    "print(\"recall(70, 4930, 13930, 981070) = {}\".format(recall(70, 4930, 13930, 981070)))\n",
    "print(\"f1_score(70, 4930, 13930, 981070) = {}\".format(f1_score(70, 4930, 13930, 981070)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd5ad82",
   "metadata": {},
   "source": [
    "sklearn's confusion matrix and classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f074086b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 1]\n",
      " [0 3]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "y_true = [\"cat\", \"ant\", \"cat\", \"cat\", \"ant\", \"cat\"]\n",
    "y_pred = [\"ant\", \"ant\", \"cat\", \"cat\", \"ant\", \"cat\"]\n",
    "#predictive value 를 왼쪽 행에 놓기 위하여 matrix 를 Transpose\n",
    "print(confusion_matrix(y_true, y_pred, labels=[\"ant\", \"cat\"]).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977ba567",
   "metadata": {},
   "source": [
    "|               | ant  | cat  |\n",
    "| ------------- | ---- | ---- |\n",
    "| predict \"ant\" | 2    | 1    |\n",
    "| predict \"cat\" | 0    | 3    |\n",
    "\n",
    "| *ant 기준*        | ant  | not ant |\n",
    "| ----------------- | ---- | ------- |\n",
    "| predict \"ant\"     | 2(TP)    | 1(FP)       |\n",
    "| predict \"not ant\" | 0(FP)    | 3(TN)       |\n",
    "\n",
    "| *cat 기준*        | not cat | cat  |\n",
    "| ----------------- | ------- | ---- |\n",
    "| predict \"not cat\" | 2(TN)       | 1(FN)    |\n",
    "| predict \"cat\"     | 0(FP)       | 3(TP)    |\n",
    "\n",
    "> confusion matrix 에서 예측기준에 따라 TP, FP, TN, FN 이 달라진다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d9f1acfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ant       0.67      1.00      0.80         2\n",
      "         cat       1.00      0.75      0.86         4\n",
      "\n",
      "    accuracy                           0.83         6\n",
      "   macro avg       0.83      0.88      0.83         6\n",
      "weighted avg       0.89      0.83      0.84         6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred, labels=[\"ant\", \"cat\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4b82591a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 1 0]\n",
      " [0 3 0]\n",
      " [0 0 2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ant       0.67      1.00      0.80         2\n",
      "         cat       1.00      0.75      0.86         4\n",
      "        bird       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.88         8\n",
      "   macro avg       0.89      0.92      0.89         8\n",
      "weighted avg       0.92      0.88      0.88         8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "y_true = [\"cat\", \"ant\", \"cat\", \"cat\", \"ant\", \"cat\", \"bird\", \"bird\"]\n",
    "y_pred = [\"ant\", \"ant\", \"cat\", \"cat\", \"ant\", \"cat\", \"bird\", \"bird\"]\n",
    "print(confusion_matrix(y_true, y_pred, labels=[\"ant\", \"cat\", \"bird\"]).T)\n",
    "print(classification_report(y_true, y_pred, labels=[\"ant\", \"cat\", \"bird\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
